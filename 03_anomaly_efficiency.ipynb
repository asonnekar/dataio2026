{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Efficiency Benchmarking & Anomaly Detection\n",
    "\n",
    "**OSU Campus Energy Analysis — Data I/O 2026 Advanced Track**\n",
    "\n",
    "This notebook identifies energy waste opportunities and anomalies across campus. We compute Energy Use Intensity (EUI) benchmarks, detect off-hours waste, apply statistical and ML-based anomaly detection, and quantify potential savings.\n",
    "\n",
    "**Narrative arc**: \"We identified specific buildings with quantifiable savings opportunities, backed by peer benchmarking and anomaly evidence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:27.756201Z",
     "iopub.status.busy": "2026-02-07T18:18:27.756083Z",
     "iopub.status.idle": "2026-02-07T18:18:29.055797Z",
     "shell.execute_reply": "2026-02-07T18:18:29.055306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path('/Users/Siddarth/Data IO/processed')\n",
    "\n",
    "# Per documentation: energy utilities only for EUI and consumption analysis\n",
    "ENERGY_UTILITIES = ['ELECTRICITY', 'STEAM', 'HEAT', 'GAS', 'COOLING', 'OIL28SEC']\n",
    "\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:29.057138Z",
     "iopub.status.busy": "2026-02-07T18:18:29.056991Z",
     "iopub.status.idle": "2026-02-07T18:18:34.027157Z",
     "shell.execute_reply": "2026-02-07T18:18:34.026323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy data: 8,812,752 rows\n",
      "Buildings in data: 285\n",
      "Utilities: ['COOLING', 'ELECTRICITY', 'GAS', 'HEAT', 'OIL28SEC', 'STEAM']\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "meter_all = pd.read_parquet(DATA_DIR / 'meter_all_utilities.parquet')\n",
    "meter_all['date'] = pd.to_datetime(meter_all['date'])\n",
    "daily_weather = pd.read_parquet(DATA_DIR / 'daily_weather.parquet')\n",
    "daily_weather['date'] = pd.to_datetime(daily_weather['date'])\n",
    "buildings = pd.read_parquet(DATA_DIR / 'buildings.parquet')\n",
    "\n",
    "# Filter to energy utilities only (per documentation: power utilities for peak demand, not EUI)\n",
    "energy_data = meter_all[meter_all['utility'].isin(ENERGY_UTILITIES)].copy()\n",
    "\n",
    "print(f'Energy data: {len(energy_data):,} rows')\n",
    "print(f'Buildings in data: {energy_data[\"simscode\"].nunique()}')\n",
    "print(f'Utilities: {sorted(energy_data[\"utility\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Energy Use Intensity (EUI) Calculation\n",
    "\n",
    "EUI = Annual Energy / Gross Area (kWh/sqft/year). Per the documentation, we normalize energy-based utilities by square footage for fair comparison. We compute separate EUIs for each energy utility to avoid mixing units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:34.029507Z",
     "iopub.status.busy": "2026-02-07T18:18:34.029376Z",
     "iopub.status.idle": "2026-02-07T18:18:34.994313Z",
     "shell.execute_reply": "2026-02-07T18:18:34.993742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COOLING: 86 buildings, median EUI = 5.65, mean EUI = 126185.92, range = [0.00, 8991995.36]\n",
      "ELECTRICITY: 270 buildings, median EUI = 3.13, mean EUI = 10867.07, range = [0.00, 1266988.82]\n",
      "GAS: 147 buildings, median EUI = 1.60, mean EUI = 14116475.16, range = [0.00, 2074751506.33]\n",
      "HEAT: 132 buildings, median EUI = 3.36, mean EUI = 1630.52, range = [0.00, 196689.06]\n",
      "OIL28SEC: 1 buildings, median EUI = 1418145.31, mean EUI = 1418145.31, range = [1418145.31, 1418145.31]\n",
      "STEAM: 27 buildings, median EUI = 11.71, mean EUI = 500247069.43, range = [0.00, 5452530712.03]\n"
     ]
    }
   ],
   "source": [
    "# Compute annual consumption per building per utility\n",
    "annual_bldg = energy_data.groupby(['simscode', 'utility', 'buildingname', 'campusname', 'grossarea']).agg(\n",
    "    annual_total=('readingvalue', 'sum'),\n",
    "    n_days=('readingvalue', 'count'),\n",
    "    n_meters=('meterid', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Only keep buildings with reasonable data coverage (>300 days)\n",
    "annual_bldg = annual_bldg[annual_bldg['n_days'] >= 300].copy()\n",
    "annual_bldg['grossarea'] = pd.to_numeric(annual_bldg['grossarea'], errors='coerce')\n",
    "\n",
    "# Compute EUI (only where grossArea is valid and > 0)\n",
    "annual_bldg['eui'] = np.where(\n",
    "    (annual_bldg['grossarea'] > 0) & annual_bldg['grossarea'].notna(),\n",
    "    annual_bldg['annual_total'] / annual_bldg['grossarea'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Summary by utility\n",
    "for util in sorted(annual_bldg['utility'].unique()):\n",
    "    sub = annual_bldg[annual_bldg['utility'] == util].dropna(subset=['eui'])\n",
    "    if len(sub) > 0:\n",
    "        print(f'{util}: {len(sub)} buildings, median EUI = {sub[\"eui\"].median():.2f}, '\n",
    "              f'mean EUI = {sub[\"eui\"].mean():.2f}, range = [{sub[\"eui\"].min():.2f}, {sub[\"eui\"].max():.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:34.995651Z",
     "iopub.status.busy": "2026-02-07T18:18:34.995563Z",
     "iopub.status.idle": "2026-02-07T18:18:35.087141Z",
     "shell.execute_reply": "2026-02-07T18:18:35.086629Z"
    }
   },
   "outputs": [],
   "source": [
    "# EUI distribution for electricity (largest utility)\n",
    "elec_eui = annual_bldg[(annual_bldg['utility'] == 'ELECTRICITY') & annual_bldg['eui'].notna()].copy()\n",
    "elec_eui = elec_eui[elec_eui['eui'] > 0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "clip_val = elec_eui['eui'].quantile(0.98)\n",
    "axes[0].hist(elec_eui['eui'].clip(upper=clip_val), bins=40, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(elec_eui['eui'].median(), color='red', linestyle='--', linewidth=2, label=f'Median: {elec_eui[\"eui\"].median():.1f}')\n",
    "axes[0].set_title('Electricity EUI Distribution (kWh/sqft/year)', fontweight='bold')\n",
    "axes[0].set_xlabel('EUI (kWh/sqft/year)')\n",
    "axes[0].set_ylabel('Number of Buildings')\n",
    "axes[0].legend()\n",
    "\n",
    "# Top and bottom performers\n",
    "top10 = elec_eui.nlargest(10, 'eui')\n",
    "bot10 = elec_eui.nsmallest(10, 'eui')\n",
    "combined = pd.concat([top10, bot10])\n",
    "combined['label'] = combined['buildingname'].apply(lambda x: str(x)[:30] if pd.notna(x) else 'Unknown')\n",
    "colors = ['coral'] * 10 + ['green'] * 10\n",
    "combined = combined.sort_values('eui')\n",
    "axes[1].barh(combined['label'], combined['eui'], color=colors[:len(combined)])\n",
    "axes[1].set_title('Top 10 Highest & Lowest Electricity EUI Buildings', fontweight='bold')\n",
    "axes[1].set_xlabel('EUI (kWh/sqft/year)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peer Benchmarking\n",
    "\n",
    "We group buildings into peer groups by campus + size tier + age tier, then rank each building's EUI within its peer group. Buildings that significantly exceed their peer median are candidates for efficiency improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:35.088829Z",
     "iopub.status.busy": "2026-02-07T18:18:35.088715Z",
     "iopub.status.idle": "2026-02-07T18:18:35.104245Z",
     "shell.execute_reply": "2026-02-07T18:18:35.103769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buildings with EUI > 1.5x peer median: 84\n",
      "                                     buildingname campusname          size_tier          eui  peer_median_eui   eui_vs_peer\n",
      "                   OSU Electric Substation (0079)   Columbus    Medium (10-50k) 1.266989e+06         3.024960 418844.867584\n",
      "                    Substation West Campus (0134)   Columbus       Small (<10k) 6.198429e+05         3.020524 205210.381258\n",
      "                    Waterman - Turf Shed 1 (0992)   Columbus       Small (<10k) 5.267399e+05         3.020524 174386.908166\n",
      "  Energy Advancement and Innovation Center (1044)   Columbus    Large (50-150k) 4.336126e+05         3.179032 136397.684855\n",
      "                       Dreese Laboratories (0279)   Columbus Very Large (>150k) 8.337157e+04         2.532811  32916.612203\n",
      "             McPherson Chemical Laboratory (0053)   Columbus    Large (50-150k) 2.006869e+03         3.179032    631.282925\n",
      "        Chilled Water Plant, East Regional (0376)   Columbus    Medium (10-50k) 1.272475e+02         3.024960     42.065862\n",
      "       Chiller Plant, South Campus Central (0388)   Columbus    Large (50-150k) 1.076677e+02         3.179032     33.868090\n",
      "                              Hopkins Hall (0149)   Columbus    Large (50-150k) 9.669794e+01         3.179032     30.417414\n",
      "Newman and Wolfrom Laboratory of Chemistry (0147)   Columbus    Large (50-150k) 6.808238e+01         3.179032     21.416071\n",
      "                     McCracken Power Plant (0069)   Columbus    Large (50-150k) 5.823113e+01         3.179032     18.317252\n",
      "    Field Hockey and Outdoor Tennis Office (0230)   Columbus       Small (<10k) 5.455364e+01         3.020524     18.060985\n",
      "                          Scott Laboratory (0148)   Columbus Very Large (>150k) 3.931706e+01         2.532811     15.523090\n",
      "                        Generator Building (0377)   Columbus       Small (<10k) 1.681733e+01         3.020524      5.567688\n",
      "                               Power House (0130)   Columbus       Small (<10k) 1.653712e+01         3.020524      5.474917\n"
     ]
    }
   ],
   "source": [
    "# Create peer groups for electricity EUI\n",
    "elec_eui_peer = elec_eui.copy()\n",
    "elec_eui_peer['building_age'] = pd.to_numeric(\n",
    "    buildings.set_index('buildingnumber').loc[elec_eui_peer['simscode'].values, 'building_age'].values,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Size tiers\n",
    "elec_eui_peer['size_tier'] = pd.cut(elec_eui_peer['grossarea'], \n",
    "                                      bins=[0, 10000, 50000, 150000, np.inf],\n",
    "                                      labels=['Small (<10k)', 'Medium (10-50k)', 'Large (50-150k)', 'Very Large (>150k)'])\n",
    "# Age tiers\n",
    "elec_eui_peer['age_tier'] = pd.cut(elec_eui_peer['building_age'],\n",
    "                                    bins=[0, 25, 50, 100, np.inf],\n",
    "                                    labels=['New (0-25yr)', 'Mid (25-50yr)', 'Old (50-100yr)', 'Historic (>100yr)'])\n",
    "\n",
    "# Compute peer group stats\n",
    "peer_groups = elec_eui_peer.groupby(['campusname', 'size_tier']).agg(\n",
    "    peer_median_eui=('eui', 'median'),\n",
    "    peer_mean_eui=('eui', 'mean'),\n",
    "    peer_count=('eui', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Merge back\n",
    "elec_eui_peer = elec_eui_peer.merge(peer_groups, on=['campusname', 'size_tier'], how='left')\n",
    "elec_eui_peer['eui_vs_peer'] = elec_eui_peer['eui'] / elec_eui_peer['peer_median_eui']\n",
    "\n",
    "# Flag buildings >1.5x peer median\n",
    "inefficient = elec_eui_peer[elec_eui_peer['eui_vs_peer'] > 1.5].sort_values('eui_vs_peer', ascending=False)\n",
    "print(f'Buildings with EUI > 1.5x peer median: {len(inefficient)}')\n",
    "print(inefficient[['buildingname', 'campusname', 'size_tier', 'eui', 'peer_median_eui', 'eui_vs_peer']].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:35.105482Z",
     "iopub.status.busy": "2026-02-07T18:18:35.105399Z",
     "iopub.status.idle": "2026-02-07T18:18:35.175255Z",
     "shell.execute_reply": "2026-02-07T18:18:35.174534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Peer benchmarking visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# EUI by campus (boxplot)\n",
    "campus_data = elec_eui_peer.dropna(subset=['campusname', 'eui'])\n",
    "campus_order = campus_data.groupby('campusname')['eui'].median().sort_values(ascending=False).index\n",
    "sns.boxplot(data=campus_data, y='campusname', x='eui', order=campus_order, ax=axes[0],\n",
    "            showfliers=False, palette='Set2')\n",
    "axes[0].set_title('Electricity EUI by Campus', fontweight='bold')\n",
    "axes[0].set_xlabel('EUI (kWh/sqft/year)')\n",
    "axes[0].set_ylabel('')\n",
    "\n",
    "# EUI by size tier\n",
    "size_data = elec_eui_peer.dropna(subset=['size_tier', 'eui'])\n",
    "sns.boxplot(data=size_data, y='size_tier', x='eui', ax=axes[1], showfliers=False, palette='Set3')\n",
    "axes[1].set_title('Electricity EUI by Building Size Tier', fontweight='bold')\n",
    "axes[1].set_xlabel('EUI (kWh/sqft/year)')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Off-Hours Waste Analysis\n",
    "\n",
    "Many buildings consume nearly as much energy at night and on weekends as during occupied hours. The **base load ratio** (night avg / day avg) identifies buildings that \"never turn off.\" A ratio above 0.7 suggests excessive off-hours consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:35.177218Z",
     "iopub.status.busy": "2026-02-07T18:18:35.177094Z",
     "iopub.status.idle": "2026-02-07T18:18:39.677318Z",
     "shell.execute_reply": "2026-02-07T18:18:39.676294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buildings with base load ratio > 0.7 (\"never turn off\"): 93\n",
      "                               buildingname campusname  mean_base_ratio  weekend_weekday_ratio  weekday_avg\n",
      "   Parking Garage - Ohio Union North (0288)   Columbus         0.949363               0.996518     6.392768\n",
      "                         Hughes Hall (0042)   Columbus         0.903913               0.996294     3.733986\n",
      "                    Evans Laboratory (0150)   Columbus         0.890823               0.985079    35.185762\n",
      "             Bulk Chemical Warehouse (0362)   Columbus         0.884962               0.995613     9.783591\n",
      "   Telecommunications Network Center (0379)   Columbus         0.884135               0.996931    45.407208\n",
      "           Physics Research Building (0070)   Columbus         0.884074               0.978274   126.155432\n",
      "                         Sisson Hall (0080)   Columbus         0.875737               0.971526    48.272201\n",
      "  Parker Food Science and Technology (0064)   Columbus         0.853717               0.982004    81.891245\n",
      "       McPherson Chemical Laboratory (0053)   Columbus         0.849909               1.017317 13411.575392\n",
      "                      Riffe Building (0266)   Columbus         0.848693               1.010765    48.732458\n",
      "        Parking Garage - Twelfth Ave (0387)   Columbus         0.843589               0.979233     9.753777\n",
      "                         Drinko Hall (0049)   Columbus         0.839272               0.958103    24.103896\n",
      "Animal House Kinnear Research Center (0174)   Columbus         0.839151               0.992457     2.903462\n",
      "                       Paterson Hall (0103)   Columbus         0.835243               0.988611    17.957531\n",
      "             Galbreath Equine Center (0282)   Columbus         0.828449               0.953244     5.244813\n"
     ]
    }
   ],
   "source": [
    "# Use readingwindowmin (daily minimum 15-min reading) as proxy for base load\n",
    "# and readingwindowmax as proxy for peak load\n",
    "elec_data = meter_all[meter_all['utility'] == 'ELECTRICITY'].copy()\n",
    "elec_data['day_of_week'] = elec_data['date'].dt.dayofweek  # 0=Mon, 6=Sun\n",
    "elec_data['is_weekend'] = elec_data['day_of_week'].isin([5, 6])\n",
    "\n",
    "# Base load ratio = min / max (per day). Closer to 1 = flat load = never turns off\n",
    "elec_data['base_load_ratio'] = elec_data['readingwindowmin'] / elec_data['readingwindowmax']\n",
    "elec_data['base_load_ratio'] = elec_data['base_load_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Building-level base load ratio\n",
    "bldg_base = elec_data.groupby(['simscode', 'buildingname', 'campusname', 'grossarea']).agg(\n",
    "    mean_base_ratio=('base_load_ratio', 'mean'),\n",
    "    weekday_avg=('readingvalue', lambda x: x[~elec_data.loc[x.index, 'is_weekend']].mean()),\n",
    "    weekend_avg=('readingvalue', lambda x: x[elec_data.loc[x.index, 'is_weekend']].mean()),\n",
    "    n_days=('readingvalue', 'count')\n",
    ").reset_index()\n",
    "\n",
    "bldg_base = bldg_base[bldg_base['n_days'] >= 300]\n",
    "bldg_base['weekend_weekday_ratio'] = bldg_base['weekend_avg'] / bldg_base['weekday_avg']\n",
    "bldg_base['weekend_weekday_ratio'] = bldg_base['weekend_weekday_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Buildings that never turn off (base load ratio > 0.7)\n",
    "always_on = bldg_base[bldg_base['mean_base_ratio'] > 0.7].sort_values('mean_base_ratio', ascending=False)\n",
    "print(f'Buildings with base load ratio > 0.7 (\"never turn off\"): {len(always_on)}')\n",
    "print(always_on[['buildingname', 'campusname', 'mean_base_ratio', 'weekend_weekday_ratio', 'weekday_avg']].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:39.681880Z",
     "iopub.status.busy": "2026-02-07T18:18:39.681709Z",
     "iopub.status.idle": "2026-02-07T18:18:39.747510Z",
     "shell.execute_reply": "2026-02-07T18:18:39.747110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buildings above the diagonal use MORE energy on weekends — potential scheduling issue.\n",
      "Buildings near the diagonal never scale down — potential off-hours waste.\n"
     ]
    }
   ],
   "source": [
    "# Off-hours waste visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Base load ratio distribution\n",
    "valid_base = bldg_base['mean_base_ratio'].dropna()\n",
    "valid_base = valid_base[(valid_base >= 0) & (valid_base <= 1)]\n",
    "axes[0].hist(valid_base, bins=40, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0.7, color='red', linestyle='--', linewidth=2, label='Threshold (0.7)')\n",
    "axes[0].set_title('Distribution of Base Load Ratio (min/max)', fontweight='bold')\n",
    "axes[0].set_xlabel('Base Load Ratio (1.0 = completely flat load)')\n",
    "axes[0].set_ylabel('Number of Buildings')\n",
    "axes[0].legend()\n",
    "\n",
    "# Weekend vs weekday\n",
    "valid_ww = bldg_base.dropna(subset=['weekday_avg', 'weekend_avg'])\n",
    "valid_ww = valid_ww[(valid_ww['weekday_avg'] > 0) & (valid_ww['weekend_avg'] > 0)]\n",
    "max_val = max(valid_ww['weekday_avg'].quantile(0.95), valid_ww['weekend_avg'].quantile(0.95))\n",
    "axes[1].scatter(valid_ww['weekday_avg'], valid_ww['weekend_avg'], alpha=0.4, s=20, c='coral')\n",
    "axes[1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='Equal usage')\n",
    "axes[1].set_title('Weekend vs Weekday Average Electricity', fontweight='bold')\n",
    "axes[1].set_xlabel('Weekday Avg (kWh/day)')\n",
    "axes[1].set_ylabel('Weekend Avg (kWh/day)')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(0, max_val * 1.1)\n",
    "axes[1].set_ylim(0, max_val * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Buildings above the diagonal use MORE energy on weekends — potential scheduling issue.')\n",
    "print('Buildings near the diagonal never scale down — potential off-hours waste.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anomaly Detection (Statistical)\n",
    "\n",
    "We use Z-score and IQR methods to flag individual days with anomalous consumption spikes or drops per meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:39.749679Z",
     "iopub.status.busy": "2026-02-07T18:18:39.749517Z",
     "iopub.status.idle": "2026-02-07T18:18:44.419917Z",
     "shell.execute_reply": "2026-02-07T18:18:44.419058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score anomalies (|z| > 3): 21,931 days (0.58%)\n",
      "IQR anomalies: 100,326 days (2.68%)\n"
     ]
    }
   ],
   "source": [
    "# Z-score anomaly detection per meter\n",
    "elec_data_clean = elec_data[elec_data['readingvalue'] > 0].copy()\n",
    "\n",
    "# Compute per-meter mean and std\n",
    "meter_stats = elec_data_clean.groupby('meterid')['readingvalue'].agg(['mean', 'std']).reset_index()\n",
    "meter_stats.columns = ['meterid', 'meter_mean', 'meter_std']\n",
    "meter_stats = meter_stats[meter_stats['meter_std'] > 0]  # skip constant meters\n",
    "\n",
    "elec_anom = elec_data_clean.merge(meter_stats, on='meterid', how='inner')\n",
    "elec_anom['z_score'] = (elec_anom['readingvalue'] - elec_anom['meter_mean']) / elec_anom['meter_std']\n",
    "\n",
    "# Flag anomalies at |z| > 3\n",
    "elec_anom['is_anomaly_zscore'] = elec_anom['z_score'].abs() > 3\n",
    "n_anomalies = elec_anom['is_anomaly_zscore'].sum()\n",
    "print(f'Z-score anomalies (|z| > 3): {n_anomalies:,} days ({100*n_anomalies/len(elec_anom):.2f}%)')\n",
    "\n",
    "# IQR method\n",
    "meter_iqr = elec_data_clean.groupby('meterid')['readingvalue'].agg(\n",
    "    lambda x: x.quantile(0.75) - x.quantile(0.25)\n",
    ").reset_index()\n",
    "meter_iqr.columns = ['meterid', 'iqr']\n",
    "meter_q = elec_data_clean.groupby('meterid')['readingvalue'].agg(['quantile']).reset_index()\n",
    "meter_q1 = elec_data_clean.groupby('meterid')['readingvalue'].quantile(0.25).reset_index()\n",
    "meter_q3 = elec_data_clean.groupby('meterid')['readingvalue'].quantile(0.75).reset_index()\n",
    "meter_q1.columns = ['meterid', 'q1']\n",
    "meter_q3.columns = ['meterid', 'q3']\n",
    "\n",
    "elec_anom = elec_anom.merge(meter_iqr, on='meterid', how='left')\n",
    "elec_anom = elec_anom.merge(meter_q1, on='meterid', how='left')\n",
    "elec_anom = elec_anom.merge(meter_q3, on='meterid', how='left')\n",
    "elec_anom['is_anomaly_iqr'] = (elec_anom['readingvalue'] < elec_anom['q1'] - 1.5 * elec_anom['iqr']) | \\\n",
    "                                (elec_anom['readingvalue'] > elec_anom['q3'] + 1.5 * elec_anom['iqr'])\n",
    "\n",
    "n_iqr = elec_anom['is_anomaly_iqr'].sum()\n",
    "print(f'IQR anomalies: {n_iqr:,} days ({100*n_iqr/len(elec_anom):.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:44.422568Z",
     "iopub.status.busy": "2026-02-07T18:18:44.422443Z",
     "iopub.status.idle": "2026-02-07T18:18:45.024103Z",
     "shell.execute_reply": "2026-02-07T18:18:45.023646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize anomaly distribution over time\n",
    "anom_by_date = elec_anom.groupby('date')['is_anomaly_zscore'].sum().reset_index()\n",
    "anom_by_date.columns = ['date', 'n_anomalies']\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "axes[0].bar(anom_by_date['date'], anom_by_date['n_anomalies'], color='coral', alpha=0.7, width=1)\n",
    "axes[0].set_title('Daily Count of Z-Score Anomalies (|z| > 3) Across All Meters', fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Anomalous Meters')\n",
    "import matplotlib.dates as mdates\n",
    "axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "# Anomaly rate by meter (which meters are most problematic?)\n",
    "meter_anom_rate = elec_anom.groupby('meterid').agg(\n",
    "    n_anomalies=('is_anomaly_zscore', 'sum'),\n",
    "    n_total=('is_anomaly_zscore', 'count'),\n",
    "    building=('buildingname', 'first')\n",
    ").reset_index()\n",
    "meter_anom_rate['anom_rate'] = meter_anom_rate['n_anomalies'] / meter_anom_rate['n_total']\n",
    "top_anom_meters = meter_anom_rate.nlargest(15, 'anom_rate')\n",
    "\n",
    "axes[1].barh(top_anom_meters['building'].apply(lambda x: str(x)[:30] if pd.notna(x) else ''),\n",
    "             top_anom_meters['anom_rate'] * 100, color='steelblue', edgecolor='black')\n",
    "axes[1].set_title('Top 15 Meters by Anomaly Rate', fontweight='bold')\n",
    "axes[1].set_xlabel('% of Days with Anomalous Readings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection (Machine Learning)\n",
    "\n",
    "We apply Isolation Forest — an unsupervised ML algorithm — using multiple features beyond simple thresholds. This detects multivariate anomalies that statistical methods miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:45.025836Z",
     "iopub.status.busy": "2026-02-07T18:18:45.025729Z",
     "iopub.status.idle": "2026-02-07T18:18:48.147976Z",
     "shell.execute_reply": "2026-02-07T18:18:48.147308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Isolation Forest Anomaly Summary (top 30 buildings) ===\n",
      "simscode                                   buildingname  n_anomalies  anom_pct  total_days\n",
      "      82                            Ohio Stadium (0082)           19  5.248619         362\n",
      "      79                 OSU Electric Substation (0079)           19  5.248619         362\n",
      "     308                          Rightmire Hall (0308)           19  5.248619         362\n",
      "     171                               Dodd Hall (0171)           19  5.248619         362\n",
      "     277                             Graves Hall (0277)           19  5.248619         362\n",
      "      24                             Postle Hall (0024)           19  5.248619         362\n",
      "      89                               Doan Hall (0089)           19  5.248619         362\n",
      "     372                Brain and Spine Hospital (0372)           19  5.248619         362\n",
      "     353                     Ross Heart Hospital (0353)           19  5.248619         362\n",
      "      70               Physics Research Building (0070)           19  5.248619         362\n",
      "     299               Veterinary Medical Center (0299)           19  5.248619         362\n",
      "      81                    Schottenstein Center (0081)           19  5.248619         362\n",
      "     248                                    CBEC (0248)           19  5.248619         362\n",
      "     246 Recreation and Physical Activity Center (0246)           19  5.248619         362\n",
      "     276            Biological Sciences Building (0276)           19  5.248619         362\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for Isolation Forest\n",
    "# Aggregate to building-day level with multiple features\n",
    "bldg_day = elec_data.groupby(['simscode', 'date']).agg(\n",
    "    daily_kwh=('readingvalue', 'sum'),\n",
    "    min_reading=('readingwindowmin', 'mean'),\n",
    "    max_reading=('readingwindowmax', 'mean'),\n",
    "    stddev=('readingwindowstandarddeviation', 'mean'),\n",
    "    pct_missing=('pct_missing', 'mean'),\n",
    "    buildingname=('buildingname', 'first')\n",
    ").reset_index()\n",
    "\n",
    "bldg_day = bldg_day.merge(daily_weather[['date', 'temp_mean']], on='date', how='inner')\n",
    "bldg_day['day_of_week'] = bldg_day['date'].dt.dayofweek\n",
    "bldg_day['load_range'] = bldg_day['max_reading'] - bldg_day['min_reading']\n",
    "bldg_day['base_load_ratio'] = np.where(bldg_day['max_reading'] > 0,\n",
    "                                        bldg_day['min_reading'] / bldg_day['max_reading'], np.nan)\n",
    "\n",
    "# Run Isolation Forest on the top 30 most consuming buildings\n",
    "top30 = bldg_day.groupby('simscode')['daily_kwh'].sum().nlargest(30).index\n",
    "iso_results = []\n",
    "\n",
    "for bldg_id in top30:\n",
    "    bdf = bldg_day[bldg_day['simscode'] == bldg_id].copy()\n",
    "    feature_cols = ['daily_kwh', 'stddev', 'base_load_ratio', 'temp_mean', 'day_of_week']\n",
    "    bdf_features = bdf[feature_cols].dropna()\n",
    "    \n",
    "    if len(bdf_features) < 60:\n",
    "        continue\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(bdf_features)\n",
    "    \n",
    "    iso = IsolationForest(contamination=0.05, random_state=42, n_estimators=100)\n",
    "    bdf.loc[bdf_features.index, 'iso_anomaly'] = iso.fit_predict(X_scaled)\n",
    "    bdf.loc[bdf_features.index, 'iso_score'] = iso.decision_function(X_scaled)\n",
    "    \n",
    "    n_anom = (bdf['iso_anomaly'] == -1).sum()\n",
    "    iso_results.append({\n",
    "        'simscode': bldg_id,\n",
    "        'buildingname': bdf['buildingname'].iloc[0],\n",
    "        'n_anomalies': n_anom,\n",
    "        'anom_pct': 100 * n_anom / len(bdf_features),\n",
    "        'total_days': len(bdf_features)\n",
    "    })\n",
    "\n",
    "iso_summary = pd.DataFrame(iso_results)\n",
    "print('=== Isolation Forest Anomaly Summary (top 30 buildings) ===')\n",
    "print(iso_summary.sort_values('n_anomalies', ascending=False).head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Change-Point Detection (CUSUM)\n",
    "\n",
    "CUSUM (Cumulative Sum) detects step-changes in consumption patterns — indicating equipment failure, retrofit, or occupancy changes. This goes beyond daily anomalies to find persistent shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:48.149793Z",
     "iopub.status.busy": "2026-02-07T18:18:48.149695Z",
     "iopub.status.idle": "2026-02-07T18:18:48.218489Z",
     "shell.execute_reply": "2026-02-07T18:18:48.217750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSUM Change-Point Detection ===\n",
      "Energy Advancement and Innovation C: 7 change-points — ['Nov 10', 'Nov 11', 'Nov 13', 'Nov 17', 'Nov 24']\n",
      "OSU Electric Substation (0079): 6 change-points — ['Jan 12', 'Feb 23', 'Mar 05', 'Jun 25', 'Sep 14']\n",
      "Dreese Laboratories (0279): 4 change-points — ['Nov 16', 'Nov 27', 'Dec 09', 'Dec 30']\n",
      "Substation West Campus (0134): 5 change-points — ['Apr 06', 'May 26', 'Jun 26', 'Nov 16', 'Dec 10']\n",
      "Waterman - Turf Shed 1 (0992): 1 change-points — ['Nov 23']\n",
      "McPherson Chemical Laboratory (0053: 18 change-points — ['Apr 06', 'Apr 09', 'Apr 12', 'Apr 15', 'Apr 18']\n",
      "Hopkins Hall (0149): 1 change-points — ['Dec 24']\n",
      "Scott Laboratory (0148): 1 change-points — ['Dec 14']\n",
      "Chiller Plant, South Campus Central: 25 change-points — ['Jan 12', 'Jan 23', 'Feb 04', 'Feb 15', 'Feb 26']\n",
      "James Cancer Hospital (0375): 5 change-points — ['May 26', 'Aug 22', 'Oct 07', 'Nov 02', 'Dec 17']\n",
      "McCracken Power Plant (0069): 24 change-points — ['Jan 11', 'Jan 21', 'Jan 31', 'Feb 09', 'Feb 19']\n",
      "Biomedical Research Tower (0112): 24 change-points — ['Jan 16', 'Feb 02', 'Feb 19', 'Mar 07', 'Apr 17']\n",
      "Rhodes Hall (0354): 15 change-points — ['Mar 08', 'Apr 11', 'Jun 09', 'Jun 17', 'Jun 26']\n",
      "Chilled Water Plant, East Regional : 22 change-points — ['Jan 20', 'Feb 07', 'Feb 21', 'Mar 25', 'Jun 14']\n",
      "Newman and Wolfrom Laboratory of Ch: 1 change-points — ['Dec 25']\n",
      "Ohio Stadium (0082): 22 change-points — ['Jan 16', 'Feb 03', 'Feb 15', 'Mar 18', 'Mar 26']\n",
      "Recreation and Physical Activity Ce: 18 change-points — ['Jan 23', 'May 09', 'Jun 14', 'Jun 20', 'Jun 27']\n",
      "CBEC (0248): 13 change-points — ['Mar 13', 'Mar 20', 'Mar 23', 'Mar 26', 'Apr 07']\n",
      "Schottenstein Center (0081): 21 change-points — ['Jan 09', 'Feb 12', 'Apr 12', 'May 31', 'Jun 24']\n",
      "Veterinary Medical Center (0299): 22 change-points — ['Jan 12', 'Jan 22', 'Feb 03', 'Feb 16', 'Mar 02']\n"
     ]
    }
   ],
   "source": [
    "def detect_cusum(series, threshold=5.0, drift=0.5):\n",
    "    \"\"\"CUSUM change-point detection. Returns indices of detected change points.\"\"\"\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    if std == 0:\n",
    "        return []\n",
    "    \n",
    "    normalized = (series - mean) / std\n",
    "    s_pos = np.zeros(len(normalized))\n",
    "    s_neg = np.zeros(len(normalized))\n",
    "    change_points = []\n",
    "    \n",
    "    for i in range(1, len(normalized)):\n",
    "        s_pos[i] = max(0, s_pos[i-1] + normalized.iloc[i] - drift)\n",
    "        s_neg[i] = max(0, s_neg[i-1] - normalized.iloc[i] - drift)\n",
    "        if s_pos[i] > threshold or s_neg[i] > threshold:\n",
    "            change_points.append(i)\n",
    "            s_pos[i] = 0\n",
    "            s_neg[i] = 0\n",
    "    \n",
    "    return change_points\n",
    "\n",
    "# Run CUSUM on top 20 electricity consumers\n",
    "top20 = bldg_day.groupby('simscode')['daily_kwh'].sum().nlargest(20).index\n",
    "cusum_results = []\n",
    "\n",
    "for bldg_id in top20:\n",
    "    bdf = bldg_day[bldg_day['simscode'] == bldg_id].sort_values('date')\n",
    "    if len(bdf) < 60:\n",
    "        continue\n",
    "    cps = detect_cusum(bdf['daily_kwh'])\n",
    "    cusum_results.append({\n",
    "        'simscode': bldg_id,\n",
    "        'buildingname': bdf['buildingname'].iloc[0],\n",
    "        'n_change_points': len(cps),\n",
    "        'change_dates': [bdf.iloc[cp]['date'] for cp in cps[:5]] if cps else []\n",
    "    })\n",
    "\n",
    "cusum_df = pd.DataFrame(cusum_results)\n",
    "print('=== CUSUM Change-Point Detection ===')\n",
    "for _, row in cusum_df.iterrows():\n",
    "    name = str(row['buildingname'])[:35] if pd.notna(row['buildingname']) else row['simscode']\n",
    "    dates = [d.strftime('%b %d') if hasattr(d, 'strftime') else str(d) for d in row['change_dates']]\n",
    "    print(f'{name}: {row[\"n_change_points\"]} change-points — {dates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:48.220929Z",
     "iopub.status.busy": "2026-02-07T18:18:48.220795Z",
     "iopub.status.idle": "2026-02-07T18:18:48.262427Z",
     "shell.execute_reply": "2026-02-07T18:18:48.261747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red lines indicate CUSUM-detected step changes in consumption pattern.\n"
     ]
    }
   ],
   "source": [
    "# Visualize CUSUM for a building with change points\n",
    "bldg_with_cp = cusum_df[cusum_df['n_change_points'] > 0].iloc[0] if len(cusum_df[cusum_df['n_change_points'] > 0]) > 0 else None\n",
    "\n",
    "if bldg_with_cp is not None:\n",
    "    bdf = bldg_day[bldg_day['simscode'] == bldg_with_cp['simscode']].sort_values('date')\n",
    "    cps = detect_cusum(bdf['daily_kwh'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    ax.plot(bdf['date'], bdf['daily_kwh'], color='steelblue', alpha=0.6, linewidth=0.8)\n",
    "    ax.plot(bdf['date'], bdf['daily_kwh'].rolling(14).mean(), color='navy', linewidth=2, label='14-day rolling mean')\n",
    "    \n",
    "    for cp in cps:\n",
    "        ax.axvline(bdf.iloc[cp]['date'], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    name = str(bldg_with_cp['buildingname'])[:40] if pd.notna(bldg_with_cp['buildingname']) else bldg_with_cp['simscode']\n",
    "    ax.set_title(f'CUSUM Change-Point Detection: {name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Daily Electricity (kWh)')\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f'Red lines indicate CUSUM-detected step changes in consumption pattern.')\n",
    "else:\n",
    "    print('No buildings with detected change points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Savings Quantification\n",
    "\n",
    "We estimate potential savings for buildings identified as inefficient, combining peer benchmarking and off-hours waste analysis. We use a conservative electricity rate of $0.08/kWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:48.264348Z",
     "iopub.status.busy": "2026-02-07T18:18:48.264216Z",
     "iopub.status.idle": "2026-02-07T18:18:48.271697Z",
     "shell.execute_reply": "2026-02-07T18:18:48.271127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Savings Potential from Peer Benchmarking ===\n",
      "If every above-median building reduced EUI to its peer median:\n",
      "  Total savings: 68653.5 million kWh/year\n",
      "  Estimated cost savings: $5492.28 million/year\n",
      "\n",
      "Top 10 buildings by savings potential:\n",
      "                                   buildingname campusname          eui  peer_median_eui   excess_kwh  savings_dollars\n",
      "Energy Advancement and Innovation Center (1044)   Columbus 4.336126e+05         3.179032 2.869194e+10     2.295355e+09\n",
      "                 OSU Electric Substation (0079)   Columbus 1.266989e+06         3.024960 1.715499e+10     1.372399e+09\n",
      "                     Dreese Laboratories (0279)   Columbus 8.337157e+04         2.532811 1.545912e+10     1.236730e+09\n",
      "                  Substation West Campus (0134)   Columbus 6.198429e+05         3.020524 6.034141e+09     4.827313e+08\n",
      "                  Waterman - Turf Shed 1 (0992)   Columbus 5.267399e+05         3.020524 1.000800e+09     8.006400e+07\n",
      "           McPherson Chemical Laboratory (0053)   Columbus 2.006869e+03         3.179032 2.357561e+08     1.886049e+07\n",
      "                            Hopkins Hall (0149)   Columbus 9.669794e+01         3.179032 1.030148e+07     8.241185e+05\n",
      "                        Scott Laboratory (0148)   Columbus 3.931706e+01         2.532811 9.651267e+06     7.721014e+05\n",
      "     Chiller Plant, South Campus Central (0388)   Columbus 1.076677e+02         3.179032 8.678415e+06     6.942732e+05\n",
      "                   McCracken Power Plant (0069)   Columbus 5.823113e+01         3.179032 6.063549e+06     4.850839e+05\n"
     ]
    }
   ],
   "source": [
    "ELEC_RATE = 0.08  # $/kWh (conservative campus rate)\n",
    "\n",
    "# Savings from peer benchmarking: if each building reduced EUI to peer median\n",
    "savings_peer = elec_eui_peer[elec_eui_peer['eui_vs_peer'] > 1.0].copy()\n",
    "savings_peer['excess_eui'] = savings_peer['eui'] - savings_peer['peer_median_eui']\n",
    "savings_peer['excess_kwh'] = savings_peer['excess_eui'] * savings_peer['grossarea']\n",
    "savings_peer['savings_dollars'] = savings_peer['excess_kwh'] * ELEC_RATE\n",
    "savings_peer = savings_peer.sort_values('excess_kwh', ascending=False)\n",
    "\n",
    "total_savings_kwh = savings_peer['excess_kwh'].sum()\n",
    "total_savings_dollars = savings_peer['savings_dollars'].sum()\n",
    "\n",
    "print(f'=== Savings Potential from Peer Benchmarking ===')\n",
    "print(f'If every above-median building reduced EUI to its peer median:')\n",
    "print(f'  Total savings: {total_savings_kwh/1e6:.1f} million kWh/year')\n",
    "print(f'  Estimated cost savings: ${total_savings_dollars/1e6:.2f} million/year')\n",
    "print(f'\\nTop 10 buildings by savings potential:')\n",
    "print(savings_peer[['buildingname', 'campusname', 'eui', 'peer_median_eui', 'excess_kwh', 'savings_dollars']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:48.273263Z",
     "iopub.status.busy": "2026-02-07T18:18:48.273157Z",
     "iopub.status.idle": "2026-02-07T18:18:48.326534Z",
     "shell.execute_reply": "2026-02-07T18:18:48.325945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Savings visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 10 savings opportunities\n",
    "top10_savings = savings_peer.head(10).copy()\n",
    "top10_savings['label'] = top10_savings['buildingname'].apply(lambda x: str(x)[:30] if pd.notna(x) else 'Unknown')\n",
    "axes[0].barh(top10_savings['label'], top10_savings['savings_dollars'] / 1000, color='green', edgecolor='black')\n",
    "axes[0].set_title('Top 10 Buildings: Annual Savings Potential', fontweight='bold')\n",
    "axes[0].set_xlabel('Estimated Savings ($1,000/year)')\n",
    "\n",
    "# Cumulative savings (Pareto-style)\n",
    "savings_sorted = savings_peer.sort_values('excess_kwh', ascending=False)\n",
    "savings_sorted['cum_savings'] = savings_sorted['excess_kwh'].cumsum()\n",
    "savings_sorted['cum_pct'] = savings_sorted['cum_savings'] / total_savings_kwh * 100\n",
    "axes[1].plot(range(1, len(savings_sorted) + 1), savings_sorted['cum_pct'], 'o-', color='steelblue', markersize=3)\n",
    "axes[1].axhline(80, color='red', linestyle='--', alpha=0.5, label='80% of total')\n",
    "n_80 = (savings_sorted['cum_pct'] <= 80).sum()\n",
    "axes[1].axvline(n_80, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title(f'Cumulative Savings: {n_80} Buildings = 80% of Total', fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Buildings (ranked by savings)')\n",
    "axes[1].set_ylabel('Cumulative % of Total Savings')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Scorecard\n",
    "\n",
    "Per-meter data quality assessment: % missing readings, % filtered readings, and consecutive gap detection. This informs which meters need sensor maintenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:48.328417Z",
     "iopub.status.busy": "2026-02-07T18:18:48.328310Z",
     "iopub.status.idle": "2026-02-07T18:18:49.769850Z",
     "shell.execute_reply": "2026-02-07T18:18:49.769127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Quality Scorecard ===\n",
      "data_quality_grade\n",
      "A (Perfect)     783\n",
      "B (Good)         84\n",
      "C (Fair)         32\n",
      "D (Poor)         58\n",
      "F (Critical)     58\n",
      "\n",
      "Worst 10 meters (highest missing rate):\n",
      " meterid                       buildingname     utility  mean_pct_missing  total_days data_quality_grade\n",
      "  245952   Baker Systems Engineering (0280) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246000      Pump House - Cannon Dr (1010) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246025 Comprehensive Cancer Center (0363) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246263                  Parks Hall (0273) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246264                  Parks Hall (0273) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246265                  Parks Hall (0273) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246386   Veterinary Medical Center (0299) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246387   Veterinary Medical Center (0299) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246388   Veterinary Medical Center (0299) ELECTRICITY             100.0           0       F (Critical)\n",
      "  246389   Veterinary Medical Center (0299) ELECTRICITY             100.0           0       F (Critical)\n"
     ]
    }
   ],
   "source": [
    "# Data quality scorecard per meter\n",
    "quality = meter_all.groupby(['meterid', 'simscode', 'buildingname', 'utility']).agg(\n",
    "    total_days=('readingvalue', 'count'),\n",
    "    mean_pct_missing=('pct_missing', 'mean'),\n",
    "    max_pct_missing=('pct_missing', 'max'),\n",
    "    days_with_missing=('pct_missing', lambda x: (x > 0).sum()),\n",
    "    mean_pct_filtered=('pct_filtered', 'mean'),\n",
    "    mean_reading=('readingvalue', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "quality['data_quality_grade'] = np.where(\n",
    "    quality['mean_pct_missing'] == 0, 'A (Perfect)',\n",
    "    np.where(quality['mean_pct_missing'] < 5, 'B (Good)',\n",
    "    np.where(quality['mean_pct_missing'] < 25, 'C (Fair)',\n",
    "    np.where(quality['mean_pct_missing'] < 50, 'D (Poor)', 'F (Critical)'))))\n",
    "\n",
    "print('=== Data Quality Scorecard ===')\n",
    "print(quality['data_quality_grade'].value_counts().sort_index().to_string())\n",
    "\n",
    "# Worst meters\n",
    "worst = quality.nlargest(10, 'mean_pct_missing')\n",
    "print(f'\\nWorst 10 meters (highest missing rate):')\n",
    "print(worst[['meterid', 'buildingname', 'utility', 'mean_pct_missing', 'total_days', 'data_quality_grade']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T18:18:49.772289Z",
     "iopub.status.busy": "2026-02-07T18:18:49.772172Z",
     "iopub.status.idle": "2026-02-07T18:18:49.784289Z",
     "shell.execute_reply": "2026-02-07T18:18:49.783791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved savings_potential.parquet and data_quality_scorecard.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save results for Notebook 5\n",
    "try:\n",
    "    savings_peer.to_parquet(DATA_DIR / 'savings_potential.parquet')\n",
    "    quality.to_parquet(DATA_DIR / 'data_quality_scorecard.parquet')\n",
    "    print('Saved savings_potential.parquet and data_quality_scorecard.parquet')\n",
    "except NameError:\n",
    "    print('Dataframes not found, cell execution order issue?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **EUI Benchmarking**: Wide variation in Electricity EUI across campus. Some buildings consume several times more per sqft than their peers.\n",
    "2. **Peer Comparison**: Buildings exceeding 1.5x their peer group median EUI represent the highest-impact efficiency opportunities.\n",
    "3. **Off-Hours Waste**: A significant number of buildings maintain high base load ratios (>0.7), meaning they \"never turn off\" — indicating scheduling or controls issues.\n",
    "4. **Anomaly Detection**: Both Z-score and Isolation Forest methods identify days with unusual consumption patterns, potentially indicating equipment malfunction or operational issues.\n",
    "5. **Change-Point Detection**: CUSUM identifies persistent shifts in building consumption — useful for detecting equipment failures or successful retrofits.\n",
    "6. **Savings Potential**: Reducing above-median buildings to peer median EUI yields millions of kWh and substantial cost savings annually. A Pareto analysis shows that a small number of buildings account for the majority of savings potential.\n",
    "7. **Data Quality**: The majority of meters have excellent data quality, but specific meters with chronic missing data should be prioritized for sensor maintenance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSU Energy (Python 3)",
   "language": "python",
   "name": "osu-energy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
